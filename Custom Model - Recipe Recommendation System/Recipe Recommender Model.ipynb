{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5fe223e-188b-4d0a-8c00-46dce075296d",
   "metadata": {},
   "source": [
    "### Recipe Recommender Model\n",
    "A more complicated model that I'll be using for my Recipe Book application. Its job is to look at the different recipes that the user has created or favourited in the past, and using that, recommend them other recipes when they browse for recipes that other people have made.\n",
    "\n",
    "Input: User-made recipes, including names, description, ingredients, and steps. Along with this, recipes that other people have made.\n",
    "\n",
    "Output: A score given to each recipe for how relevant they seem to the user.\n",
    "\n",
    "Success Rate Goal: 90% accuracy/confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e9443e-a400-4caa-9d1d-963a1bab57c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc2f10a-cc90-495f-9feb-1b16417a558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting torch to use GPU acceleration if possible.\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "torch.set_default_device(device)\n",
    "print(f\"Using device: {torch.get_default_device()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d9b61a-5975-49f6-8fac-564a69344e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== DATA COLLECTION ======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d37df0-9c3f-4491-9069-2acc6c462203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all of the data.\n",
    "lines = []\n",
    "\n",
    "with open(\"data.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        lines.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a9da3f-b7dd-4551-a37d-7dee2b3029ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing - Ensuring that the dataset is properly loaded and that there are no extreme indexing errors.\n",
    "cIndex = 0\n",
    "while cIndex < len(lines):\n",
    "    if len(lines[cIndex]) > 100:\n",
    "        print(cIndex)\n",
    "\n",
    "    cIndex += 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe9d41-9541-4cac-bc3e-714293431b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse all of the data into recipes.\n",
    "recipes = []\n",
    "\n",
    "index = 0\n",
    "\n",
    "while index < len(lines) - 3:\n",
    "    recipes.append({\n",
    "        \"name\": lines[index],\n",
    "        \"description\": lines[index + 1],\n",
    "        \"ingredients\": lines[index + 2],\n",
    "        \"steps\": lines[index + 3]\n",
    "    })\n",
    "\n",
    "    index += 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d9dcc-4b89-4c11-ace3-2b6988783c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training and testing samples.\n",
    "SAMPLES = 1000\n",
    "TRAIN_RATIO = 0.9\n",
    "\n",
    "RECIPE_MEDIAN = 5\n",
    "RECIPE_VARIANCE = 3\n",
    "\n",
    "RECIPE_TEST_MEDIAN = 10\n",
    "RECIPE_TEST_VARIANCE = 5\n",
    "\n",
    "dataSamples = []\n",
    "\n",
    "for i in range(SAMPLES):\n",
    "    cDataSample = [[], []]\n",
    "    \n",
    "    recipeCount = random.choice(range(RECIPE_MEDIAN - RECIPE_VARIANCE, RECIPE_MEDIAN + RECIPE_VARIANCE + 1))\n",
    "    testCount = random.choice(range(RECIPE_TEST_MEDIAN - RECIPE_TEST_VARIANCE, RECIPE_TEST_MEDIAN + RECIPE_TEST_VARIANCE + 1))\n",
    "\n",
    "    for j in range(recipeCount + testCount):\n",
    "        chosenRecipe = copy.deepcopy(random.choice(recipes))\n",
    "        chosenRecipe[\"favourites\"] = random.choice(range(0, 1001))\n",
    "        cDataSample[0 if (j >= recipeCount) else 1].append(chosenRecipe)\n",
    "\n",
    "    dataSamples.append(cDataSample)\n",
    "\n",
    "xTrain = dataSamples[:int(SAMPLES * TRAIN_RATIO)]\n",
    "xTest = dataSamples[int(SAMPLES * TRAIN_RATIO):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be0e88-a5c8-45a3-8ceb-70d681fed262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== MODEL CONSTRUCTION (PROOF OF CONCEPT) ======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69e6c7-7e29-4599-b617-8c1463a1babc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def compute(self, recipes):\n",
    "        def get_recipe_distances(recipe1, recipe2):\n",
    "            def calculate_sentence_embedding(text):\n",
    "                inputs = self.tokenizer(text, return_tensors=\"pt\", truncation = True, padding = True, max_length = 512)\n",
    "    \n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model(**inputs)\n",
    "    \n",
    "                return outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "            tags = { # Tag - Multiplier\n",
    "                \"name\": 1.5,\n",
    "                \"description\": 1.0,\n",
    "                \"ingredients\": 0.8,\n",
    "                \"steps\": 0.5\n",
    "            }\n",
    "\n",
    "            total = 0\n",
    "\n",
    "            for tag in tags.keys():\n",
    "                emb1 = calculate_sentence_embedding(recipe1[\"name\"])\n",
    "                emb2 = calculate_sentence_embedding(recipe2[\"name\"])\n",
    "        \n",
    "                total += nn.functional.cosine_similarity(emb1, emb2) * tags[tag]\n",
    "\n",
    "            return total\n",
    "\n",
    "        recipeScores = copy.deepcopy(recipes[1])\n",
    "\n",
    "        for recipe in recipeScores:\n",
    "            recipe[\"score\"] = 0\n",
    "\n",
    "            for userRecipe in recipes[0]:\n",
    "                recipe[\"score\"] += get_recipe_distances(recipe, userRecipe)\n",
    "\n",
    "            recipe[\"score\"] = recipe[\"score\"].item() * (np.log10(recipe[\"favourites\"] + 1) + 1)\n",
    "\n",
    "        recipeScores = sorted(recipeScores, key = lambda x: x[\"score\"])\n",
    "        \n",
    "        return recipeScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a9604-7030-46c1-9e8d-5c746da5be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255f4445-af28-492b-aae0-f605a5fe4ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compute(xTrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c39bd45-013f-44c1-a4be-e5514866d8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
